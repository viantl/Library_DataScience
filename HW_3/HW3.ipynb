{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a58d4a",
   "metadata": {},
   "source": [
    "## 1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e58a4e",
   "metadata": {},
   "source": [
    "    micro - показывает значение метрики для всей выбори целиком, может быть полезным показателем, если необходимо сгладить значение высокочастотного класса.\n",
    "    macro - используется при сбалансированности классов или если значение низкочастотных классов не важны. Рассчитывается как среднеарифметическое метрики каждого класса;\n",
    "    weighted - используется при несбалансированных данных, чтобы подчеркнуть влияние каждого из классов, опираясь на количество его представителей. Рассчитывается как средневзвешеное метрики по числу выборок на каждый класс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7af25",
   "metadata": {},
   "source": [
    "## 2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029c37d",
   "metadata": {},
   "source": [
    "    2.1. Особенности алгоритма xgboost:\n",
    "        - Эффективность ресурсов времени и памяти;\n",
    "        - различные стратегии обработки пропущенных данных;\n",
    "        - блочная структура для поддержки распараллеливания обучения деревьев;\n",
    "        - продолжение обучения для дообучения на новых данных\n",
    "\n",
    "    2.2 Особенности алгоритма lightgbm:\n",
    "        - градиентная односторонняя выборка — модификация градиентного бустинга, который фокусирует внимание на тех учебных примерах, которые приводят к большему градиенту, в свою очередь, ускоряя обучение и уменьшая вычислительную сложность метода;\n",
    "        - Объединение взаимоисключающих признаков — это подход объединения разрежённых взаимоисключающих признаков, таких как категориальные переменные входных данных, закодированные унитарным кодированием.\n",
    "    2.3 Особенности алгоритма CatBoost:\n",
    "        - Позволяет проводить обучение на нескольких GPU;\n",
    "        - Позволяет получить отличные результаты с параметрами по умолчанию, что сокращает время, необходимое для настройки гиперпараметров;\n",
    "        - Обеспечивает повышенную точность за счет уменьшения переобучения;\n",
    "        - Умеет \"с коробки\" обрабатывать пропущенные значения;\n",
    "        - Может использоваться для регрессионных и классификационных задач."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
